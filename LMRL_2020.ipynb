{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 707",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q8888620002/Contextual_bandit/blob/master/LMRL_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<img height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\">\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5791WHkXNbc",
        "outputId": "7c8c9e71-8aca-4ab8-c427-50626508ee2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Simple example of contextual bandits simulation.\n",
        "\n",
        "Code corresponding to:\n",
        "Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks\n",
        "for Thompson Sampling, by Carlos Riquelme, George Tucker, and Jasper Snoek.\n",
        "https://arxiv.org/abs/1802.09127\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "from absl import app, flags\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/contextual_bandit_onco/deep_contextual_bandits')\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "from bandits.algorithms.bootstrapped_bnn_sampling import BootstrappedBNNSampling\n",
        "from bandits.core.contextual_bandit import run_contextual_bandit\n",
        "from bandits.algorithms.fixed_policy_sampling import FixedPolicySampling\n",
        "from bandits.algorithms.linear_full_posterior_sampling import LinearFullPosteriorSampling\n",
        "from bandits.algorithms.neural_linear_sampling import NeuralLinearPosteriorSampling\n",
        "from bandits.algorithms.parameter_noise_sampling import ParameterNoiseSampling\n",
        "from bandits.algorithms.posterior_bnn_sampling import PosteriorBNNSampling\n",
        "from bandits.data.synthetic_data_sampler import sample_linear_data\n",
        "from bandits.data.synthetic_data_sampler import sample_sparse_linear_data\n",
        "from bandits.data.synthetic_data_sampler import sample_wheel_bandit_data\n",
        "from bandits.algorithms.uniform_sampling import UniformSampling\n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "# The action index needed to be modified \n",
        "\n",
        "from bandits.algorithms.clinical_guideline import ClinicalGuideLine\n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "# Set up your file routes to the data files.\n",
        "base_route = os.getcwd()\n",
        "data_route = 'contextual_bandits/datasets'\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS.set_default('alsologtostderr', True)\n",
        "flags.DEFINE_string('logdir', '/tmp/bandits/', 'Base directory to save output')\n",
        "flags.DEFINE_string(\n",
        "    'mushroom_data',\n",
        "    os.path.join(base_route, data_route, 'mushroom.data'),\n",
        "    'Directory where Mushroom data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'financial_data',\n",
        "    os.path.join(base_route, data_route, 'raw_stock_contexts'),\n",
        "    'Directory where Financial data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'jester_data',\n",
        "    os.path.join(base_route, data_route, 'jester_data_40jokes_19181users.npy'),\n",
        "    'Directory where Jester data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'statlog_data',\n",
        "    os.path.join(base_route, data_route, 'shuttle.trn'),\n",
        "    'Directory where Statlog data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'adult_data',\n",
        "    os.path.join(base_route, data_route, 'adult.full'),\n",
        "    'Directory where Adult data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'covertype_data',\n",
        "    os.path.join(base_route, data_route, 'covtype.data'),\n",
        "    'Directory where Covertype data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'census_data',\n",
        "    os.path.join(base_route, data_route, 'USCensus1990.data.txt'),\n",
        "    'Directory where Census data is stored.')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-93c6fe7c7acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbandits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrapped_bnn_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBootstrappedBNNSampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbandits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_bandit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_contextual_bandit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbandits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_policy_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFixedPolicySampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bandits'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5uVJF9RqDc"
      },
      "source": [
        "def sample_data(num_contexts=None):\n",
        "  \"\"\"Sample data from given 'data_type'.\n",
        "\n",
        "  Args:\n",
        "    data_type: Dataset from which to sample.\n",
        "    num_contexts: Number of contexts to sample.\n",
        "\n",
        "  Returns:\n",
        "    dataset: Sampled matrix with rows: (context, reward_1, ..., reward_num_act).\n",
        "    opt_rewards: Vector of expected optimal reward for each context.\n",
        "    opt_actions: Vector of optimal action for each context.\n",
        "    num_actions: Number of available actions.\n",
        "    context_dim: Dimension of each context.\n",
        "  \"\"\"\n",
        "  \n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "\n",
        "#change the file name \n",
        "\n",
        "  data = pd.read_csv(\"/content/drive/My Drive/contextual_bandit_onco/clinic_percentile.csv\").values\n",
        "  \n",
        "#Need to change context_dim to 20 if using a different nuber of input\n",
        "\n",
        "  num_actions = 7\n",
        "  context_dim = 7\n",
        "  num_contexts = min(896, num_contexts)\n",
        "  \n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "  \n",
        "  \n",
        "  dataset, opt_cancer = sample_cancer_data(data, context_dim,\n",
        "                                           num_actions, num_contexts,\n",
        "                                           shuffle_rows=False,\n",
        "                                           shuffle_cols=False)\n",
        "  opt_rewards, opt_actions = opt_cancer\n",
        "\n",
        "\n",
        "  return dataset, opt_rewards, opt_actions, num_actions, context_dim\n",
        "\n",
        "\n",
        "\n",
        "def sample_cancer_data(dataset, context_dim, num_actions, num_contexts,\n",
        "                       shuffle_rows=False, shuffle_cols=False):\n",
        "  \"\"\"Samples bandit from dense subset of cancer dataset.\n",
        "\n",
        "  Args:\n",
        "    dataset: Route of file containing the modified UMAP dataset.\n",
        "    context_dim: Context dimension (i.e. vector with some ratings from a user).\n",
        "    num_actions: Number of actions (number of medication to predict).\n",
        "    num_contexts: Number of contexts to sample.\n",
        "    shuffle_rows: If True, rows from original dataset are shuffled.\n",
        "    shuffle_cols: Whether or not context/action jokes are randomly shuffled.\n",
        "\n",
        "  Returns:\n",
        "    dataset: Sampled matrix with rows: (context, rating_1, ..., rating_k).\n",
        "    opt_vals: Vector of deterministic optimal (reward, action) for each context.\n",
        "  \"\"\"\n",
        "  \n",
        "  print(dataset.shape)\n",
        "  \n",
        "  num_contexts = min(896, num_contexts)\n",
        "  \n",
        "  if shuffle_cols:\n",
        "    dataset = dataset[:, np.random.permutation(dataset.shape[1])]\n",
        "  if shuffle_rows:\n",
        "    np.random.shuffle(dataset)\n",
        "  \n",
        "  dataset = dataset[:num_contexts, :]\n",
        "\n",
        "  assert context_dim + num_actions == dataset.shape[1], 'Wrong data dimensions.'\n",
        "\n",
        "  opt_actions = np.argmax(dataset[:, context_dim:], axis=1)\n",
        "  \n",
        "  \n",
        "  opt_rewards = np.array([dataset[i, context_dim + a]\n",
        "                          for i, a in enumerate(opt_actions)])\n",
        "  \n",
        "  return dataset, (opt_rewards, opt_actions)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff0fEcHMXdc-"
      },
      "source": [
        "def display_results(algos, opt_rewards, opt_actions, h_rewards, t_init, actions):\n",
        "  \"\"\"Displays summary statistics of the performance of each algorithm.\"\"\"\n",
        "\n",
        "  print('---------------------------------------------------')\n",
        "  print('---------------------------------------------------')\n",
        "  print(' bandit completed after {} seconds.'.format(time.time() - t_init))\n",
        "  print('---------------------------------------------------')\n",
        "\n",
        "  performance_pairs = []\n",
        "  \n",
        "  \n",
        "  \n",
        "  action_dis = pd.DataFrame(index=range(0,896))\n",
        "  reward_table = pd.DataFrame(index=range(0,1))\n",
        "  \n",
        "  print(len(algos))\n",
        "  for j, a in enumerate(algos):\n",
        "    algo_actions = []\n",
        "    algo_actions.append([action[j] for action in actions])\n",
        "    performance_pairs.append((a.name, np.sum(h_rewards[:, j]), algo_actions ))\n",
        "\n",
        "  performance_pairs = sorted(performance_pairs,\n",
        "                             key=lambda elt: elt[1],\n",
        "                             reverse=True)\n",
        "  for i, (name, reward, algo_action) in enumerate(performance_pairs):\n",
        "    \n",
        "    print('{:3}) {:20}| \\t \\t total reward = {:10}.'.format(i, name, reward))\n",
        "\n",
        "    ### record the reward and actions\n",
        "    reward_table[name] = reward\n",
        "    action_dis[name] = algo_action[0]\n",
        "    \n",
        "    ##print([[elt, algo_action[0].count(elt)] for elt in set(algo_action[0])])\n",
        "\n",
        "  print('---------------------------------------------------')\n",
        "  print('Optimal total reward = {}.'.format(np.sum(opt_rewards)))\n",
        "  print('Frequency of optimal actions (action, frequency):')\n",
        "  print([[elt, list(opt_actions).count(elt)] for elt in set(opt_actions)])\n",
        "  print('---------------------------------------------------')\n",
        "  print('---------------------------------------------------')\n",
        "  \n",
        "  \n",
        "  \n",
        "  return reward_table, action_dis\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1GOszV8Xkkk"
      },
      "source": [
        "def main(_):\n",
        "\n",
        "  # Problem parameters \n",
        "  num_contexts = 2000\n",
        "  \n",
        "  # Create dataset  \n",
        "  \n",
        "  sampled_vals = sample_data(num_contexts)\n",
        "  \n",
        "  dataset, opt_rewards, opt_actions, num_actions, context_dim = sampled_vals\n",
        "\n",
        "  # Define hyperparameters and algorithms\n",
        "  hparams = tf.contrib.training.HParams(num_actions=num_actions)\n",
        "\n",
        "  hparams_linear = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                               context_dim=context_dim,\n",
        "                                               a0=6,\n",
        "                                               b0=6,\n",
        "                                               lambda_prior=0.25,\n",
        "                                               initial_pulls=2)\n",
        "\n",
        "  hparams_rms = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                            context_dim=context_dim,\n",
        "                                            init_scale=0.3,\n",
        "                                            activation=tf.nn.relu,\n",
        "                                            layer_sizes=[50],\n",
        "                                            batch_size=512,\n",
        "                                            activate_decay=True,\n",
        "                                            initial_lr=0.1,\n",
        "                                            max_grad_norm=5.0,\n",
        "                                            show_training=False,\n",
        "                                            freq_summary=1000,\n",
        "                                            buffer_s=-1,\n",
        "                                            initial_pulls=2,\n",
        "                                            optimizer='RMS',\n",
        "                                            reset_lr=True,\n",
        "                                            lr_decay_rate=0.5,\n",
        "                                            training_freq=50,\n",
        "                                            training_epochs=100,\n",
        "                                            p=0.95,\n",
        "                                            q=3)\n",
        "  \n",
        "  hparams_dropout = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                                context_dim=context_dim,\n",
        "                                                init_scale=0.3,\n",
        "                                                activation=tf.nn.relu,\n",
        "                                                layer_sizes=[50],\n",
        "                                                batch_size=512,\n",
        "                                                activate_decay=True,\n",
        "                                                initial_lr=0.1,\n",
        "                                                max_grad_norm=5.0,\n",
        "                                                show_training=False,\n",
        "                                                freq_summary=1000,\n",
        "                                                buffer_s=-1,\n",
        "                                                initial_pulls=2,\n",
        "                                                optimizer='RMS',\n",
        "                                                reset_lr=True,\n",
        "                                                lr_decay_rate=0.5,\n",
        "                                                training_freq=50,\n",
        "                                                training_epochs=100,\n",
        "                                                use_dropout=True,\n",
        "                                                keep_prob=0.80)\n",
        "\n",
        "  hparams_bbb = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                            context_dim=context_dim,\n",
        "                                            init_scale=0.3,\n",
        "                                            activation=tf.nn.relu,\n",
        "                                            layer_sizes=[50],\n",
        "                                            batch_size=512,\n",
        "                                            activate_decay=True,\n",
        "                                            initial_lr=0.1,\n",
        "                                            max_grad_norm=5.0,\n",
        "                                            show_training=False,\n",
        "                                            freq_summary=1000,\n",
        "                                            buffer_s=-1,\n",
        "                                            initial_pulls=2,\n",
        "                                            optimizer='RMS',\n",
        "                                            use_sigma_exp_transform=True,\n",
        "                                            cleared_times_trained=10,\n",
        "                                            initial_training_steps=100,\n",
        "                                            noise_sigma=0.1,\n",
        "                                            reset_lr=False,\n",
        "                                            training_freq=50,\n",
        "                                            training_epochs=100)\n",
        "\n",
        "  hparams_nlinear = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                                context_dim=context_dim,\n",
        "                                                init_scale=0.3,\n",
        "                                                activation=tf.nn.relu,\n",
        "                                                layer_sizes=[50],\n",
        "                                                batch_size=512,\n",
        "                                                activate_decay=True,\n",
        "                                                initial_lr=0.1,\n",
        "                                                max_grad_norm=5.0,\n",
        "                                                show_training=False,\n",
        "                                                freq_summary=1000,\n",
        "                                                buffer_s=-1,\n",
        "                                                initial_pulls=2,\n",
        "                                                reset_lr=True,\n",
        "                                                lr_decay_rate=0.5,\n",
        "                                                training_freq=1,\n",
        "                                                training_freq_network=50,\n",
        "                                                training_epochs=100,\n",
        "                                                a0=6,\n",
        "                                                b0=6,\n",
        "                                                lambda_prior=0.25)\n",
        "\n",
        "  hparams_nlinear2 = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                                 context_dim=context_dim,\n",
        "                                                 init_scale=0.3,\n",
        "                                                 activation=tf.nn.relu,\n",
        "                                                 layer_sizes=[50],\n",
        "                                                 batch_size=512,\n",
        "                                                 activate_decay=True,\n",
        "                                                 initial_lr=0.1,\n",
        "                                                 max_grad_norm=5.0,\n",
        "                                                 show_training=False,\n",
        "                                                 freq_summary=1000,\n",
        "                                                 buffer_s=-1,\n",
        "                                                 initial_pulls=2,\n",
        "                                                 reset_lr=True,\n",
        "                                                 lr_decay_rate=0.5,\n",
        "                                                 training_freq=10,\n",
        "                                                 training_freq_network=50,\n",
        "                                                 training_epochs=100,\n",
        "                                                 a0=6,\n",
        "                                                 b0=6,\n",
        "                                                 lambda_prior=0.25)\n",
        "\n",
        "  hparams_pnoise = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                               context_dim=context_dim,\n",
        "                                               init_scale=0.3,\n",
        "                                               activation=tf.nn.relu,\n",
        "                                               layer_sizes=[50],\n",
        "                                               batch_size=512,\n",
        "                                               activate_decay=True,\n",
        "                                               initial_lr=0.1,\n",
        "                                               max_grad_norm=5.0,\n",
        "                                               show_training=False,\n",
        "                                               freq_summary=1000,\n",
        "                                               buffer_s=-1,\n",
        "                                               initial_pulls=2,\n",
        "                                               optimizer='RMS',\n",
        "                                               reset_lr=True,\n",
        "                                               lr_decay_rate=0.5,\n",
        "                                               training_freq=50,\n",
        "                                               training_epochs=100,\n",
        "                                               noise_std=0.05,\n",
        "                                               eps=0.1,\n",
        "                                               d_samples=300,\n",
        "                                              )\n",
        "\n",
        "  hparams_alpha_div = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                                  context_dim=context_dim,\n",
        "                                                  init_scale=0.3,\n",
        "                                                  activation=tf.nn.relu,\n",
        "                                                  layer_sizes=[50],\n",
        "                                                  batch_size=512,\n",
        "                                                  activate_decay=True,\n",
        "                                                  initial_lr=0.1,\n",
        "                                                  max_grad_norm=5.0,\n",
        "                                                  show_training=False,\n",
        "                                                  freq_summary=1000,\n",
        "                                                  buffer_s=-1,\n",
        "                                                  initial_pulls=2,\n",
        "                                                  optimizer='RMS',\n",
        "                                                  use_sigma_exp_transform=True,\n",
        "                                                  cleared_times_trained=10,\n",
        "                                                  initial_training_steps=100,\n",
        "                                                  noise_sigma=0.1,\n",
        "                                                  reset_lr=False,\n",
        "                                                  training_freq=50,\n",
        "                                                  training_epochs=100,\n",
        "                                                  alpha=1.0,\n",
        "                                                  k=20,\n",
        "                                                  prior_variance=0.1)\n",
        "\n",
        "  hparams_gp = tf.contrib.training.HParams(num_actions=num_actions,\n",
        "                                           num_outputs=num_actions,\n",
        "                                           context_dim=context_dim,\n",
        "                                           reset_lr=False,\n",
        "                                           learn_embeddings=True,\n",
        "                                           max_num_points=1000,\n",
        "                                           show_training=False,\n",
        "                                           freq_summary=1000,\n",
        "                                           batch_size=512,\n",
        "                                           keep_fixed_after_max_obs=True,\n",
        "                                           training_freq=50,\n",
        "                                           initial_pulls=2,\n",
        "                                           training_epochs=100,\n",
        "                                           lr=0.01,\n",
        "                                           buffer_s=-1,\n",
        "                                           initial_lr=0.001,\n",
        "                                           lr_decay_rate=0.0,\n",
        "                                           optimizer='RMS',\n",
        "                                           task_latent_dim=5,\n",
        "                                           activate_decay=False)\n",
        "  \n",
        "  \n",
        "  \n",
        "  ##################################################\n",
        "  \n",
        "  #Set guideline_only to true if using only the guideline data \n",
        "  \n",
        "  hparams_clinical = tf.contrib.training.HParams(num_actions=num_actions, guideline_only=True)\n",
        "  \n",
        "  ######################################################################\n",
        "\n",
        "  algos = [\n",
        "      UniformSampling('Uniform Sampling', hparams),\n",
        "      UniformSampling('Uniform Sampling 2', hparams),\n",
        "      #FixedPolicySampling('fixed1', [0.75, 0.25], hparams),\n",
        "      #FixedPolicySampling('fixed2', [0.25, 0.75], hparams),\n",
        "      PosteriorBNNSampling('RMS', hparams_rms, 'RMSProp'),\n",
        "      ### RMS net\n",
        "      PosteriorBNNSampling('Dropout', hparams_dropout, 'RMSProp'),\n",
        "      ### Dropout\n",
        "      PosteriorBNNSampling('BBB', hparams_bbb, 'Variational'),\n",
        "      ## Stochastic Variational Inference: \n",
        "      \n",
        "      NeuralLinearPosteriorSampling('NeuralLinear', hparams_nlinear),\n",
        "      NeuralLinearPosteriorSampling('NeuralLinear2', hparams_nlinear2),\n",
        "      ### neural linaer \n",
        "      LinearFullPosteriorSampling('LinFullPost', hparams_linear),\n",
        "      \n",
        "      ### Bayesian Linear \n",
        "      BootstrappedBNNSampling('BootRMS', hparams_rms),\n",
        "      ## bootstrapped network\n",
        "      \n",
        "      ParameterNoiseSampling('ParamNoise', hparams_pnoise),\n",
        "      \n",
        "      PosteriorBNNSampling('BBAlphaDiv', hparams_alpha_div, 'AlphaDiv'),\n",
        "      \n",
        "      PosteriorBNNSampling('MultitaskGP', hparams_gp, 'GP'),\n",
        "      \n",
        "      #### Comment ClinicalGuideLine if not using clinical guideline as input feature e.g. df_percentile.csv, df_rank.csv and df_base.csv\n",
        "      \n",
        "      ClinicalGuideLine('Clinical Guideline ', hparams_clinical),\n",
        "  ]\n",
        "\n",
        "  \n",
        "  \n",
        "  ## Run contextual bandit problem\n",
        "\n",
        "    \n",
        "  t_init = time.time()\n",
        "  \n",
        "  h_actions, h_rewards = run_contextual_bandit(context_dim, num_actions, dataset, algos)\n",
        "\n",
        "  ## Display results\n",
        "  reward, action_dis = display_results(algos, opt_rewards, opt_actions, h_rewards, t_init, h_actions)\n",
        "\n",
        "  ## Store in the action folder \n",
        "\n",
        "  reward.to_csv(\"/content/drive/My Drive/contextual_bandit_onco/action_folder/reward_clinic_only_percentile_1.csv\")\n",
        "  action_dis.to_csv(\"/content/drive/My Drive/contextual_bandit_onco/action_folder/action_clinic_only_percentile_1.csv\")\n",
        "  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \n",
        "  tf.set_random_seed(5225)\t\n",
        "  np.random.seed(5225)\n",
        "  \n",
        "  tf.app.run(main) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE-VTXU2NDKC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}